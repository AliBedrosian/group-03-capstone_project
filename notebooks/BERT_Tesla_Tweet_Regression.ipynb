{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd9cea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if needed)\n",
    "# !pip install transformers datasets torch sklearn pandas numpy matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776a1d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_body</th>\n",
       "      <th>pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yup</td>\n",
       "      <td>0.118376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Massive public manipulation</td>\n",
       "      <td>0.118376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ðŸ¤£ðŸ¤£</td>\n",
       "      <td>-5.347600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prescient</td>\n",
       "      <td>-1.342455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Congratulations Tesla team on a great year!!</td>\n",
       "      <td>-0.663789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     tweet_body  pct_change\n",
       "0                                           Yup    0.118376\n",
       "1                   Massive public manipulation    0.118376\n",
       "2                                            ðŸ¤£ðŸ¤£   -5.347600\n",
       "3                                     Prescient   -1.342455\n",
       "4  Congratulations Tesla team on a great year!!   -0.663789"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tableau_ready_sentiment_data.csv\")\n",
    "df = df[['tweet_body', 'pct_change']].dropna()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e01fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(texts, max_len=64):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors='pt'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781a66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, targets):\n",
    "        self.encodings = tokenize_function(texts)  # No .tolist()\n",
    "        self.targets = torch.tensor(targets.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['target'] = self.targets[idx]\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5999fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['tweet_body'].tolist(), df['pct_change'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = TweetDataset(train_texts, train_labels)\n",
    "test_dataset = TweetDataset(test_texts, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b95d9a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTRegressor, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = output.pooler_output\n",
    "        x = self.dropout(cls_output)\n",
    "        return self.linear(x).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebc2abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTRegressor().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train_epoch(model, data_loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        targets = batch['target'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "170ed0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 236/236 [07:59<00:00,  2.03s/it, loss=8.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Avg Loss: 8.9390\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 236/236 [07:54<00:00,  2.01s/it, loss=8.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Avg Loss: 8.2758\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 236/236 [07:57<00:00,  2.03s/it, loss=6.35]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed. Avg Loss: 6.3511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # fallback version\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    epoch_iterator = tqdm(train_loader, desc=\"Training\")\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in epoch_iterator:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        targets = batch['target'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        epoch_iterator.set_postfix(loss=total_loss / (epoch_iterator.n + 1))\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} completed. Avg Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a1a91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 11.1412, RÂ²: -0.2614\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions, true_vals = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        targets = batch['target'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        true_vals.extend(targets.cpu().numpy())\n",
    "\n",
    "mse = mean_squared_error(true_vals, predictions)\n",
    "r2 = r2_score(true_vals, predictions)\n",
    "print(f\"MSE: {mse:.4f}, RÂ²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a92734-2236-4292-bd24-0eb76dc8d901",
   "metadata": {},
   "source": [
    "RÂ²: -0.2614 â†’ actually doing worse than just predicting the average every time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
